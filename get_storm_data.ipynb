{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "effff87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33953cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(url: str):\n",
    "\n",
    "    '''\n",
    "    Retrieves a list of links from the url given as a string\n",
    "    using BeautifulSoup.\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "    except requests.exceptions.HTTPError as error:\n",
    "        if error.response.status_code == 404:\n",
    "            print(f\"Error 404: url not found for {url}\")\n",
    "\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    url_list = []\n",
    "    for link in soup.find_all('a', href=True):\n",
    "        href = link['href']\n",
    "        url_list.append(href)\n",
    "\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73b0b485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_with_str(main: str, url_list: list, part: str):\n",
    "    '''\n",
    "    A function that takes as input a url as a string called main,\n",
    "    a list of urls that are strings, and a substring part to refine\n",
    "    a list of urls.\n",
    "    '''\n",
    "    url_list_with_str = []\n",
    "    for url in url_list:\n",
    "        if part in url:\n",
    "            url_list_with_str.append(main+url)\n",
    "    return url_list_with_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "462e9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = 'https://www.ncei.noaa.gov/pub/data/swdi/stormevents/csvfiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e84fe632",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = get_urls(main_url)\n",
    "url_list_details = get_url_with_str(main_url, url_list, 'details')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb05a8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/30/5r4_75_n4bz34nyphw8tfv3m0000gn/T/ipykernel_2015/1965347816.py:5: DtypeWarning: Columns (26,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, compression='gzip')\n",
      "/var/folders/30/5r4_75_n4bz34nyphw8tfv3m0000gn/T/ipykernel_2015/1965347816.py:5: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, compression='gzip')\n",
      "/var/folders/30/5r4_75_n4bz34nyphw8tfv3m0000gn/T/ipykernel_2015/1965347816.py:5: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, compression='gzip')\n",
      "/var/folders/30/5r4_75_n4bz34nyphw8tfv3m0000gn/T/ipykernel_2015/1965347816.py:5: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, compression='gzip')\n",
      "/var/folders/30/5r4_75_n4bz34nyphw8tfv3m0000gn/T/ipykernel_2015/1965347816.py:5: DtypeWarning: Columns (29,34,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file, compression='gzip')\n"
     ]
    }
   ],
   "source": [
    "df_list = []\n",
    "for url in url_list_details:\n",
    "    response = requests.get(url)\n",
    "    file = io.BytesIO(response.content)\n",
    "    df = pd.read_csv(file, compression='gzip')\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f2daa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.concat(df_list,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af6c68d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.to_csv('storm_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42e0c58b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1974189, 51)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c54b594a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10096222</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.12</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>35.17</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10120412</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>48.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.90</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>31.73</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104927</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.58</td>\n",
       "      <td>-75.70</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-75.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104928</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.60</td>\n",
       "      <td>-76.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104929</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.63</td>\n",
       "      <td>-79.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           195004         28        1445         195004       28      1445   \n",
       "1           195004         29        1530         195004       29      1530   \n",
       "2           195007          5        1800         195007        5      1800   \n",
       "3           195007          5        1830         195007        5      1830   \n",
       "4           195007         24        1440         195007       24      1440   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID         STATE  STATE_FIPS  ...  END_RANGE END_AZIMUTH  \\\n",
       "0         NaN  10096222      OKLAHOMA        40.0  ...        0.0         NaN   \n",
       "1         NaN  10120412         TEXAS        48.0  ...        0.0         NaN   \n",
       "2         NaN  10104927  PENNSYLVANIA        42.0  ...        0.0         NaN   \n",
       "3         NaN  10104928  PENNSYLVANIA        42.0  ...        0.0         NaN   \n",
       "4         NaN  10104929  PENNSYLVANIA        42.0  ...        0.0         NaN   \n",
       "\n",
       "  END_LOCATION BEGIN_LAT  BEGIN_LON END_LAT END_LON EPISODE_NARRATIVE  \\\n",
       "0          NaN     35.12     -99.20   35.17  -99.20               NaN   \n",
       "1          NaN     31.90     -98.60   31.73  -98.60               NaN   \n",
       "2          NaN     40.58     -75.70   40.65  -75.47               NaN   \n",
       "3          NaN     40.60     -76.75     NaN     NaN               NaN   \n",
       "4          NaN     41.63     -79.68     NaN     NaN               NaN   \n",
       "\n",
       "  EVENT_NARRATIVE DATA_SOURCE  \n",
       "0             NaN         PUB  \n",
       "1             NaN         PUB  \n",
       "2             NaN         PUB  \n",
       "3             NaN         PUB  \n",
       "4             NaN         PUB  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ff62b33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BEGIN_YEARMONTH', 'BEGIN_DAY', 'BEGIN_TIME', 'END_YEARMONTH',\n",
       "       'END_DAY', 'END_TIME', 'EPISODE_ID', 'EVENT_ID', 'STATE', 'STATE_FIPS',\n",
       "       'YEAR', 'MONTH_NAME', 'EVENT_TYPE', 'CZ_TYPE', 'CZ_FIPS', 'CZ_NAME',\n",
       "       'WFO', 'BEGIN_DATE_TIME', 'CZ_TIMEZONE', 'END_DATE_TIME',\n",
       "       'INJURIES_DIRECT', 'INJURIES_INDIRECT', 'DEATHS_DIRECT',\n",
       "       'DEATHS_INDIRECT', 'DAMAGE_PROPERTY', 'DAMAGE_CROPS', 'SOURCE',\n",
       "       'MAGNITUDE', 'MAGNITUDE_TYPE', 'FLOOD_CAUSE', 'CATEGORY', 'TOR_F_SCALE',\n",
       "       'TOR_LENGTH', 'TOR_WIDTH', 'TOR_OTHER_WFO', 'TOR_OTHER_CZ_STATE',\n",
       "       'TOR_OTHER_CZ_FIPS', 'TOR_OTHER_CZ_NAME', 'BEGIN_RANGE',\n",
       "       'BEGIN_AZIMUTH', 'BEGIN_LOCATION', 'END_RANGE', 'END_AZIMUTH',\n",
       "       'END_LOCATION', 'BEGIN_LAT', 'BEGIN_LON', 'END_LAT', 'END_LON',\n",
       "       'EPISODE_NARRATIVE', 'EVENT_NARRATIVE', 'DATA_SOURCE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAqEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
